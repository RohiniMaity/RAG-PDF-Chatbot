
# ğŸ¤– RAG Chatbot with PDF (Streamlit + LangChain + Groq)

This is a simple Retrieval-Augmented Generation (RAG) chatbot built using **Streamlit**, **LangChain**, **HuggingFace embeddings**, **Chroma vector store**, and **Groq's LLaMA3** LLM. It allows users to upload a PDF and ask context-aware questions based on the document.

---

## ğŸ“¦ Features

- âœ… Upload and process PDF documents  
- âœ… Chunk text using recursive character splitting  
- âœ… Embed documents using `sentence-transformers/all-MiniLM-L6-v2`  
- âœ… Store and retrieve vectors using Chroma  
- âœ… Query documents using Groq's LLaMA3 model via LangChain  
- âœ… Interactive chat interface with memory using Streamlit  

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/RohiniMaity/RAG-PDF-Chatbot.git
cd RAG-PDF-Chatbot
```

### 2. Create and activate a virtual environment (optional)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Set up environment variables

Create a `.env` file in the root directory and add your **Groq API key**:

```
GROQ_API_KEY=your_groq_api_key_here
```

---

## ğŸ“ Project Structure

```
ğŸ“¦rag-pdf-chatbot
 â”£ ğŸ“œRAG_Chatbot_Pdf.py  # Main Streamlit application
 â”£ ğŸ“œ.env                # Environment file for API key
 â”£ ğŸ“œrequirements.txt    # Python dependencies
 â”— ğŸ“œREADME.md           # This file
```

---

## â–¶ï¸ Run the App

```bash
streamlit run RAG_Chatbot_Pdf.py
```

Then, open the app in your browser (typically at [http://localhost:8501](http://localhost:8501)).

---

## ğŸ“š Tech Stack

- [Streamlit](https://streamlit.io/)
- [LangChain](https://www.langchain.com/)
- [Groq](https://groq.com/)
- [Chroma](https://www.trychroma.com/)
- [HuggingFace Embeddings](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)
- [PyPDFLoader](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf)

---

## ğŸ“ Usage Instructions

1. Use the sidebar to upload a **PDF file**.
2. Once uploaded, ask any question in the chat input box.
3. The bot will search for relevant content in the document and provide an accurate, concise response using the LLaMA3 model.

---

## ğŸ› ï¸ Notes

- Only **PDF** files are supported at the moment.
- Chroma vector store is in-memory, meaning it resets when the app restarts.
- You must have a **Groq API key** to use the LLM.

---

## ğŸ“ƒ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ™‹â€â™€ï¸ Author

**Rohini Maity**  
ğŸŒ Passionate about GenAI, RAG systems, and building intuitive AI interfaces.

---
